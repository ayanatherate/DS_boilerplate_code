{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8f7a1f-b93e-4ef8-a4d7-9da86f02203d",
   "metadata": {},
   "source": [
    "Hyperparameter tuning: Random Forest. Basic Structure remains the same. Tune and play around, as per proj. requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc060d-c3bc-4d1e-b0c3-384e8aaecd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators = [5,20,50,100] # number of trees in the random forest\n",
    "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
    "min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
    "bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "'max_features': max_features,\n",
    "\n",
    "'max_depth': max_depth,\n",
    "\n",
    "'min_samples_split': min_samples_split,\n",
    "\n",
    "'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae538a7-79f6-4889-814c-c88f327c2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator = reg,param_distributions = random_grid,\n",
    "               n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38689617-1087-4568-895c-2d6cc119d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35574b-2cbc-410f-b85d-5082bb0ca49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19ab7c-456f-433a-8606-7b084065a6a8",
   "metadata": {},
   "source": [
    "OpenCV extract facial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60522204-0db2-45ca-a456-c9ed6bff5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deepface import DeepFace \n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import os \n",
    "\n",
    "\n",
    "\n",
    "face_cascade_name = cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml'\n",
    "face_cascade = cv2.CascadeClassifier(r'C:\\Users\\User\\Desktop\\haarcascade_frontalface_default.xml')\n",
    "points_list=[]\n",
    "emo_dict_list=[]\n",
    "\n",
    "\n",
    "for file in os.listdir(r\"C:\\Users\\User\\Downloads\\Video_test_folder\"):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        path=os.path.join(r\"C:\\Users\\User\\Downloads\\Video_test_folder\", file)\n",
    "        points=0\n",
    "        emo_dict={'worry':0,'happy':0,'neutral':0,'sad':0,'surprise':0,'confident':0,'nervous':0,'disgust':0}\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        \n",
    "        time=1\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS) \n",
    "        cap.set(5,100)# OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        while(1):\n",
    "            ret,frame = cap.read()\n",
    "            if ret:\n",
    "                frame = cv2.resize(frame, (1280, 720))\n",
    "                labels = []\n",
    "                gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "            else:\n",
    "            \n",
    "                break\n",
    "\n",
    "            #faces = face_cascade.detectMultiScale(frame,scaleFactor = 1.3, minNeighbors = 4 )\n",
    "            output = DeepFace.analyze(frame, enforce_detection=False, actions=['emotion','dominant_emotion'] )\n",
    "            #print(output)\n",
    "            \n",
    "          \n",
    "            text=str(emotion)\n",
    "            for (x,y,w,h) in faces :\n",
    "                cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "                roi_gray = gray[y:y+h,x:x+w]\n",
    "                roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "                if np.sum([roi_gray])!=0:\n",
    "                    roi = roi_gray.astype('float')/255.0\n",
    "                    roi = img_to_array(roi)\n",
    "                    roi = np.expand_dims(roi,axis=0)\n",
    "            \n",
    "                    cv2.putText(frame,text,(x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), thickness = 2)\n",
    "                else:\n",
    "                    cv2.putText(frame,'No Face Found',(20,60),cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "                \n",
    "            cv2.imshow(\"Video\", frame)\n",
    "            if cv2.waitKey(time) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()   \n",
    "        final_score=points/frame_count\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print(\"Thus the final score obtained by the candidate based on the video evaluation is \"+str(final_score))\n",
    "        print(emo_dict)\n",
    "        points_list.append(final_score)\n",
    "        emo_dict_list.append(emo_dict)    \n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
